Common:
  use_residual: True
  use_layer_norm: True
  loader_workers: 2
  dim: 64
  eval_every: 5
  wd: 0.0
  lr: 0.001
  max_epochs: 100
  mlp_activation_hidden: relu
  mlp_activation_final: relu
<<<<<<< HEAD
  val_batch_size: 1024
=======
  val_batch_size: 1
>>>>>>> add_batched
  accum_grad: 1
  lr_factor: .7
  repeat: 1
  optim_type: Adam
  seed: 0
  take_last: False
  dtype: float32
  edgefeat_dim: 0
Task_specific:
  SW:
    Ring:
      batch_size: 5
      mlp_layers: 3
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
<<<<<<< HEAD
=======
      max_epochs: 100
      num_train_samples: 5
      num_test_samples: 5
      use_residual: False
      use_layer_norm: False
      lr_factor: .9
    one_radius:
       batch_size: 128
       mlp_layers: 3 # 0/3
       mlp_activation_hidden: lrelu
       mlp_activation_final: lrelu
       max_epochs: 200
       self_loop_weight: 0.2
       lr_factor: .9
       mlp_init: ~
       num_train_samples: 10000
       num_test_samples: 1000
    two_radius:
       batch_size: 128
       mlp_layers: 3 # 0/3
       mlp_activation_hidden: lrelu
       mlp_activation_final: lrelu
       max_epochs: 200
       self_loop_weight: 0.2
       lr_factor: .9
       mlp_init: ~
       num_train_samples: 10000
       num_test_samples: 10
    TwoCycles:
      batch_size: 5
      mlp_layers: 3
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
      max_epochs: 200
      num_train_samples: 5
      num_test_samples: 5
      use_residual: False
      use_layer_norm: False
    Path:
      batch_size: 5
      mlp_layers: 3
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
      max_epochs: 200
      num_train_samples: 5
      num_test_samples: 5
      use_residual: False
      use_layer_norm: False
    KPaths:
      batch_size: 5
      mlp_layers: 3
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
>>>>>>> add_batched
      max_epochs: 200
      num_train_samples: 5
      num_test_samples: 5
      use_residual: False
      use_layer_norm: False
    CliquePath:
      batch_size: 5
      max_epochs: 200
      mlp_layers: 3
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
      num_train_samples: 5
      num_test_samples: 5
      use_residual: False
      use_layer_norm: False
      lr_factor: .9
    CrossRing:
      batch_size: 5
      lr_factor: .9
      mlp_layers: 3
      max_epochs: 200
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
      num_train_samples: 5
      num_test_samples: 5
      use_residual: False
      use_layer_norm: False
    Tree:
      train_fraction: 0.8
      lr_factor: 0.9
      mlp_layers: 0
      max_epochs: 500
      train_fraction: 0.8
      mlp_activation_hidden: relu
      mlp_activation_final: relu
      num_train_samples: 32000
      num_test_samples: 1000
      use_residual: False
      use_layer_norm: False
  GAT: 
    Ring:
      dim: 64
      lr_factor: .9
      batch_size: 5
      wd: 0.0
<<<<<<< HEAD
      lr: 0.001
      max_epochs: 80
=======
      lr: 0.005
      max_epochs: 100
>>>>>>> add_batched
      optim_type: AdamW
      use_residual: False
      use_layer_norm: False
      eval_every: 5
      num_train_samples: 5
      num_test_samples: 5
  GIN: 
    MUTAG:
      dim: 128
      edgefeat_dim: 128
      lr_factor: .9
      mlp_layers: 3
      batch_size: 16
      wd: 0.0001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001
      max_epochs: 80
      optim_type: AdamW
      use_residual: True
      use_layer_norm: True
      eval_every: 5
      seed: 15
      take_last: True
    Ring:
      dim: 64
      lr_factor: .7
      batch_size: 5
      wd: 0.0
<<<<<<< HEAD
      lr: 0.001
      max_epochs: 80
=======
      lr: 0.005
      max_epochs: 200
>>>>>>> add_batched
      optim_type: AdamW
      use_residual: False
      use_layer_norm: False
      eval_every: 5
      num_train_samples: 5
      num_test_samples: 5
<<<<<<< HEAD

=======
      val_batch_size: 5
    two_radius:
       batch_size: 128
       mlp_activation_hidden: lrelu
       mlp_activation_final: lrelu
       max_epochs: 200
       self_loop_weight: 0.2
       lr_factor: .9
       mlp_init: ~
       num_train_samples: 10000
       num_test_samples: 1000
    one_radius:
      batch_size: 128
      mlp_layers: 3 # 0/3
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
      max_epochs: 100
      self_loop_weight: 0.2
      lr_factor: .9
      mlp_init: ~
      num_train_samples: 10000
      num_test_samples: 100
>>>>>>> add_batched
  GCN: 
    Ring:
      dim: 64
      lr_factor: .7
      batch_size: 5
      wd: 0.0
<<<<<<< HEAD
      lr: 0.001
      max_epochs: 80
=======
      lr: 0.005
      max_epochs: 200
>>>>>>> add_batched
      optim_type: AdamW
      use_residual: False
      use_layer_norm: False
      eval_every: 5
      num_train_samples: 5
      num_test_samples: 5
  GGNN: 
<<<<<<< HEAD
    MUTAG:
      dim: 128
      edgefeat_dim: 128
      lr_factor: .9
=======
    two_radius:
       batch_size: 128
       max_epochs: 200            
       lr_factor: .9
       num_train_samples: 10000
       num_test_samples: 1000
    Ring:
      dim: 64
      lr_factor: .7
>>>>>>> add_batched
      mlp_layers: 3
      batch_size: 5
      wd: 0.0
      lr: 0.005
      max_epochs: 80
      optim_type: AdamW
      use_residual: False
      use_layer_norm: False
      eval_every: 5
      num_train_samples: 5
      num_test_samples: 5
  SAGE: 
    Ring:
      dim: 64
      lr_factor: .7
      mlp_layers: 3
      batch_size: 5
      wd: 0.0
      lr: 0.005
      max_epochs: 80
      optim_type: AdamW
      use_residual: False
      use_layer_norm: False
      eval_every: 5
      num_train_samples: 5
      num_test_samples: 5
  Transformer: 
    Ring:
      dim: 64
      lr_factor: .9
      mlp_layers: 3
      batch_size: 16
      lr: 0.001
      max_epochs: 80
      optim_type: AdamW
      use_residual: True
      use_layer_norm: True
      eval_every: 5
      num_train_samples: 5
      num_test_samples: 5
    one_radius:
      batch_size: 128
      mlp_layers: 3 # 0/3
      mlp_activation_hidden: lrelu
      mlp_activation_final: lrelu
      max_epochs: 5
      self_loop_weight: 0.2
      lr_factor: .9
      mlp_init: ~
      num_train_samples: 10000
      num_test_samples: 100